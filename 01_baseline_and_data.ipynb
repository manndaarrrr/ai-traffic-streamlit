{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58a79e84-5a44-4cba-a280-d1722bfe7a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SUMO_HOME: C:\\Program Files (x86)\\Eclipse\\Sumo\\\n",
      "Project directory: C:\\Users\\manda\\OneDrive\\Documents\\AI Traffic - Jupyter\n"
     ]
    }
   ],
   "source": [
    "# 01_baseline_and_data.ipynb\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# === IMPORTANT ===\n",
    "# If SUMO_HOME is not already set in your system environment variables,\n",
    "# you can uncomment and set it here manually:\n",
    "# os.environ[\"SUMO_HOME\"] = r\"C:\\Program Files (x86)\\Eclipse\\Sumo\"  # example for Windows\n",
    "\n",
    "SUMO_HOME = os.environ.get(\"SUMO_HOME\")\n",
    "if SUMO_HOME is None:\n",
    "    raise EnvironmentError(\"SUMO_HOME is not set. Please set it in your system or in this notebook.\")\n",
    "\n",
    "print(\"Using SUMO_HOME:\", SUMO_HOME)\n",
    "\n",
    "PROJECT_DIR = Path.cwd()\n",
    "print(\"Project directory:\", PROJECT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4ff53d5-fa59-4a04-8078-1f3824a6f9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:\n",
      "C:\\Users\\manda\\OneDrive\\Documents\\AI Traffic - Jupyter\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\")\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "734271cc-3f75-4388-8630-665f3648718b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file created at: C:\\Users\\manda\\OneDrive\\Documents\\AI Traffic - Jupyter\\my_config.sumocfg\n",
      "Exists now? True\n"
     ]
    }
   ],
   "source": [
    "# Recreate SUMO configuration file\n",
    "\n",
    "CONFIG_FILE = PROJECT_DIR / \"my_config.sumocfg\"\n",
    "\n",
    "config_xml = f\"\"\"<configuration>\n",
    "    <input>\n",
    "        <net-file value=\"{NETWORK_FILE.name}\"/>\n",
    "        <route-files value=\"{ROUTE_FILE.name}\"/>\n",
    "    </input>\n",
    "\n",
    "    <time>\n",
    "        <begin value=\"0\"/>\n",
    "        <end value=\"3600\"/>\n",
    "    </time>\n",
    "\n",
    "    <report>\n",
    "        <verbose value=\"true\"/>\n",
    "        <no-step-log value=\"true\"/>\n",
    "    </report>\n",
    "\n",
    "    <output>\n",
    "        <tripinfo-output value=\"{TRIPINFO_FILE.name}\"/>\n",
    "    </output>\n",
    "</configuration>\n",
    "\"\"\"\n",
    "\n",
    "with open(CONFIG_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(config_xml)\n",
    "\n",
    "print(\"Config file created at:\", CONFIG_FILE)\n",
    "print(\"Exists now?\", CONFIG_FILE.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8389b170-85ea-4e49-aedb-887aae436d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating my_network.net.xml from map.osm ...\n",
      "Using netconvert at: C:\\Program Files (x86)\\Eclipse\\Sumo\\bin\\netconvert.EXE\n",
      "Running netconvert with command:\n",
      "C:\\Program Files (x86)\\Eclipse\\Sumo\\bin\\netconvert.EXE --lefthand --osm-files C:\\Users\\manda\\OneDrive\\Documents\\AI Traffic - Jupyter\\map.osm -o C:\\Users\\manda\\OneDrive\\Documents\\AI Traffic - Jupyter\\my_network.net.xml --tls.guess --tls.discard-simple --ramps.guess --no-turnarounds --junctions.corner-detail 5\n",
      "\n",
      "✅ Network successfully built: C:\\Users\\manda\\OneDrive\\Documents\\AI Traffic - Jupyter\\my_network.net.xml\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import sys\n",
    "\n",
    "def build_sumo_network(osm_file: Path, net_file: Path):\n",
    "    \"\"\"\n",
    "    Convert map.osm -> my_network.net.xml using netconvert.\n",
    "    Handles Windows (.exe) and uses either PATH or SUMO_HOME.\n",
    "    \"\"\"\n",
    "    # 1) Try to find netconvert in PATH\n",
    "    netconvert_cmd = shutil.which(\"netconvert\")\n",
    "\n",
    "    if netconvert_cmd is None:\n",
    "        # 2) Fallback: build from SUMO_HOME\n",
    "        if SUMO_HOME is None:\n",
    "            raise EnvironmentError(\n",
    "                \"SUMO_HOME is not set and netconvert was not found in PATH.\\n\"\n",
    "                \"Set SUMO_HOME or add netconvert to your system PATH.\"\n",
    "            )\n",
    "\n",
    "        bin_dir = Path(SUMO_HOME) / \"bin\"\n",
    "\n",
    "        if sys.platform.startswith(\"win\"):\n",
    "            candidate = bin_dir / \"netconvert.exe\"\n",
    "        else:\n",
    "            candidate = bin_dir / \"netconvert\"\n",
    "\n",
    "        if not candidate.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"netconvert not found.\\n\"\n",
    "                f\"Tried PATH and: {candidate}\\n\"\n",
    "                f\"Check that SUMO is correctly installed in: {bin_dir}\"\n",
    "            )\n",
    "\n",
    "        netconvert_cmd = str(candidate)\n",
    "\n",
    "    print(\"Using netconvert at:\", netconvert_cmd)\n",
    "\n",
    "    cmd = [\n",
    "        netconvert_cmd,\n",
    "        \"--lefthand\",\n",
    "        \"--osm-files\", str(osm_file),\n",
    "        \"-o\", str(net_file),\n",
    "        \"--tls.guess\",\n",
    "        \"--tls.discard-simple\",\n",
    "        \"--ramps.guess\",\n",
    "        \"--no-turnarounds\",\n",
    "        \"--junctions.corner-detail\", \"5\",\n",
    "    ]\n",
    "\n",
    "    print(\"Running netconvert with command:\")\n",
    "    print(\" \".join(cmd))\n",
    "\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(\"\\nSTDERR:\\n\", result.stderr)\n",
    "        raise RuntimeError(f\"netconvert failed with code {result.returncode}\")\n",
    "\n",
    "    print(\"\\n✅ Network successfully built:\", net_file)\n",
    "\n",
    "\n",
    "# Call it ONLY if the network file does not exist yet\n",
    "if not NETWORK_FILE.exists():\n",
    "    if not OSM_FILE.exists():\n",
    "        raise FileNotFoundError(f\"OSM file not found: {OSM_FILE}\")\n",
    "    print(\"Generating my_network.net.xml from map.osm ...\")\n",
    "    build_sumo_network(OSM_FILE, NETWORK_FILE)\n",
    "else:\n",
    "    print(\"Network file already exists:\", NETWORK_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef187a54-493f-4afb-b020-5e37e0323203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSM file exists?           -> True\n",
      "Network file exists?       -> True\n",
      "Routes file exists?        -> True\n",
      ".sumocfg file exists?      -> True\n"
     ]
    }
   ],
   "source": [
    "# === CONFIG: adjust these if your filenames differ ===\n",
    "\n",
    "OSM_FILE      = PROJECT_DIR / \"map.osm\"            # your raw map\n",
    "NETWORK_FILE  = PROJECT_DIR / \"my_network.net.xml\" # will be generated\n",
    "ROUTE_FILE    = PROJECT_DIR / \"my_routes.rou.xml\"  # will be generated\n",
    "CONFIG_FILE   = PROJECT_DIR / \"my_config.sumocfg\"  # will be generated\n",
    "TRIPINFO_FILE = PROJECT_DIR / \"tripinfo_baseline.xml\"\n",
    "\n",
    "DF_SHEFF_CSV  = PROJECT_DIR / \"df_sheff.csv\"\n",
    "RAW_DFT_CSV   = PROJECT_DIR / \"dft_traffic_counts_aadf.csv\"\n",
    "\n",
    "print(\"OSM file exists?           ->\", OSM_FILE.exists())\n",
    "print(\"Network file exists?       ->\", NETWORK_FILE.exists())\n",
    "print(\"Routes file exists?        ->\", ROUTE_FILE.exists())\n",
    "print(\".sumocfg file exists?      ->\", CONFIG_FILE.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26bf063a-f779-4403-9b75-5b0714b97dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network file already exists: C:\\Users\\manda\\OneDrive\\Documents\\AI Traffic - Jupyter\\my_network.net.xml\n"
     ]
    }
   ],
   "source": [
    "def build_sumo_network(osm_file: Path, net_file: Path):\n",
    "    \"\"\"\n",
    "    Convert a raw OSM file into a SUMO .net.xml file using\n",
    "    safe, stable, UK-specific netconvert settings.\n",
    "    \"\"\"\n",
    "    netconvert = Path(SUMO_HOME) / \"bin\" / \"netconvert\"\n",
    "\n",
    "    if not netconvert.exists():\n",
    "        raise FileNotFoundError(f\"netconvert not found at: {netconvert}\")\n",
    "\n",
    "    cmd = [\n",
    "        str(netconvert),\n",
    "        \"--lefthand\",                 # UK driving\n",
    "        \"--osm-files\", str(osm_file),\n",
    "        \"-o\", str(net_file),\n",
    "\n",
    "        # Good SUMO conversion flags\n",
    "        \"--tls.guess\",                # auto detect signals\n",
    "        \"--tls.discard-simple\",       # remove trivial lights\n",
    "        \"--ramps.guess\",\n",
    "        \"--roundabouts.guess\",\n",
    "        \"--junctions.join\",           # fix broken intersections\n",
    "        \"--geometry.remove\",          # remove redundant geometry\n",
    "        \"--no-turnarounds\",\n",
    "        \"--keep-edges.min-speed\", \"1.0\",\n",
    "        \"--remove-edges.isolated\"\n",
    "    ]\n",
    "\n",
    "    print(\"Running netconvert with command:\")\n",
    "    print(\" \".join(cmd))\n",
    "\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(\"\\nSTDERR:\\n\", result.stderr)\n",
    "        raise RuntimeError(\"netconvert failed!\\n\" + result.stderr)\n",
    "\n",
    "    print(\"Network successfully built:\", net_file)\n",
    "\n",
    "\n",
    "if not NETWORK_FILE.exists():\n",
    "    print(\"Generating network file from OSM...\")\n",
    "    build_sumo_network(OSM_FILE, NETWORK_FILE)\n",
    "else:\n",
    "    print(\"Network file already exists:\", NETWORK_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ace3221-5624-4a23-8496-7eae0097723a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned df_sheff.csv not found. Building it from raw DfT file...\n",
      "Sheffield filtered shape: (2380, 10)\n",
      "Saved cleaned Sheffield file to: C:\\Users\\manda\\OneDrive\\Documents\\AI Traffic - Jupyter\\df_sheff.csv\n",
      "CLEANED Sheffield AADF Data (first 10 rows)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_point_id</th>\n",
       "      <th>year</th>\n",
       "      <th>local_authority_name</th>\n",
       "      <th>local_authority_code</th>\n",
       "      <th>road_name</th>\n",
       "      <th>road_type</th>\n",
       "      <th>road_category</th>\n",
       "      <th>all_motor_vehicles</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15873</th>\n",
       "      <td>6565</td>\n",
       "      <td>2000</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>E08000019</td>\n",
       "      <td>A57</td>\n",
       "      <td>Major</td>\n",
       "      <td>PA</td>\n",
       "      <td>6200</td>\n",
       "      <td>53.379922</td>\n",
       "      <td>-1.550482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15874</th>\n",
       "      <td>6565</td>\n",
       "      <td>2001</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>E08000019</td>\n",
       "      <td>A57</td>\n",
       "      <td>Major</td>\n",
       "      <td>PA</td>\n",
       "      <td>6245</td>\n",
       "      <td>53.379922</td>\n",
       "      <td>-1.550482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15875</th>\n",
       "      <td>6565</td>\n",
       "      <td>2002</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>E08000019</td>\n",
       "      <td>A57</td>\n",
       "      <td>Major</td>\n",
       "      <td>PA</td>\n",
       "      <td>6051</td>\n",
       "      <td>53.379922</td>\n",
       "      <td>-1.550482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15876</th>\n",
       "      <td>6565</td>\n",
       "      <td>2003</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>E08000019</td>\n",
       "      <td>A57</td>\n",
       "      <td>Major</td>\n",
       "      <td>PA</td>\n",
       "      <td>6192</td>\n",
       "      <td>53.379922</td>\n",
       "      <td>-1.550482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15877</th>\n",
       "      <td>6565</td>\n",
       "      <td>2004</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>E08000019</td>\n",
       "      <td>A57</td>\n",
       "      <td>Major</td>\n",
       "      <td>PA</td>\n",
       "      <td>6206</td>\n",
       "      <td>53.379922</td>\n",
       "      <td>-1.550482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15878</th>\n",
       "      <td>6565</td>\n",
       "      <td>2005</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>E08000019</td>\n",
       "      <td>A57</td>\n",
       "      <td>Major</td>\n",
       "      <td>PA</td>\n",
       "      <td>6218</td>\n",
       "      <td>53.379922</td>\n",
       "      <td>-1.550482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15879</th>\n",
       "      <td>6565</td>\n",
       "      <td>2006</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>E08000019</td>\n",
       "      <td>A57</td>\n",
       "      <td>Major</td>\n",
       "      <td>PA</td>\n",
       "      <td>6380</td>\n",
       "      <td>53.379922</td>\n",
       "      <td>-1.550482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15880</th>\n",
       "      <td>6565</td>\n",
       "      <td>2007</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>E08000019</td>\n",
       "      <td>A57</td>\n",
       "      <td>Major</td>\n",
       "      <td>PA</td>\n",
       "      <td>6340</td>\n",
       "      <td>53.379922</td>\n",
       "      <td>-1.550482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15881</th>\n",
       "      <td>6565</td>\n",
       "      <td>2008</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>E08000019</td>\n",
       "      <td>A57</td>\n",
       "      <td>Major</td>\n",
       "      <td>PA</td>\n",
       "      <td>6143</td>\n",
       "      <td>53.379922</td>\n",
       "      <td>-1.550482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15882</th>\n",
       "      <td>6565</td>\n",
       "      <td>2009</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>E08000019</td>\n",
       "      <td>A57</td>\n",
       "      <td>Major</td>\n",
       "      <td>PA</td>\n",
       "      <td>6357</td>\n",
       "      <td>53.379922</td>\n",
       "      <td>-1.550482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count_point_id  year local_authority_name local_authority_code  \\\n",
       "15873           6565  2000            Sheffield            E08000019   \n",
       "15874           6565  2001            Sheffield            E08000019   \n",
       "15875           6565  2002            Sheffield            E08000019   \n",
       "15876           6565  2003            Sheffield            E08000019   \n",
       "15877           6565  2004            Sheffield            E08000019   \n",
       "15878           6565  2005            Sheffield            E08000019   \n",
       "15879           6565  2006            Sheffield            E08000019   \n",
       "15880           6565  2007            Sheffield            E08000019   \n",
       "15881           6565  2008            Sheffield            E08000019   \n",
       "15882           6565  2009            Sheffield            E08000019   \n",
       "\n",
       "      road_name road_type road_category  all_motor_vehicles   latitude  \\\n",
       "15873       A57     Major            PA                6200  53.379922   \n",
       "15874       A57     Major            PA                6245  53.379922   \n",
       "15875       A57     Major            PA                6051  53.379922   \n",
       "15876       A57     Major            PA                6192  53.379922   \n",
       "15877       A57     Major            PA                6206  53.379922   \n",
       "15878       A57     Major            PA                6218  53.379922   \n",
       "15879       A57     Major            PA                6380  53.379922   \n",
       "15880       A57     Major            PA                6340  53.379922   \n",
       "15881       A57     Major            PA                6143  53.379922   \n",
       "15882       A57     Major            PA                6357  53.379922   \n",
       "\n",
       "       longitude  \n",
       "15873  -1.550482  \n",
       "15874  -1.550482  \n",
       "15875  -1.550482  \n",
       "15876  -1.550482  \n",
       "15877  -1.550482  \n",
       "15878  -1.550482  \n",
       "15879  -1.550482  \n",
       "15880  -1.550482  \n",
       "15881  -1.550482  \n",
       "15882  -1.550482  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (2380, 10)\n",
      "\n",
      "Row with max all_motor_vehicles:\n",
      "count_point_id  year local_authority_name local_authority_code road_name road_type road_category  all_motor_vehicles  latitude  longitude\n",
      "         73007  2024            Sheffield            E08000019        M1     Major            TM              137487 53.463996  -1.450033\n",
      "\n",
      "Max AADF (vehicles/day): 137487\n",
      "Assumed peak fraction: 10% of daily flow\n",
      "Computed PERIOD for randomTrips.py: 0.262 seconds between vehicles\n"
     ]
    }
   ],
   "source": [
    "def load_sheffield_data(df_sheff_path: Path, raw_dft_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load Sheffield AADF data.\n",
    "    Priority:\n",
    "      1) existing cleaned df_sheff.csv\n",
    "      2) fall back to filtering dft_traffic_counts_aadf.csv\n",
    "    \"\"\"\n",
    "    if df_sheff_path.exists():\n",
    "        print(\"Loading cleaned Sheffield dataset:\", df_sheff_path)\n",
    "        df_sheff = pd.read_csv(df_sheff_path)\n",
    "        return df_sheff\n",
    "\n",
    "    if not raw_dft_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            \"Neither df_sheff.csv nor raw dft_traffic_counts_aadf.csv found.\\n\"\n",
    "            \"Place at least one of them in the project folder.\"\n",
    "        )\n",
    "\n",
    "    print(\"Cleaned df_sheff.csv not found. Building it from raw DfT file...\")\n",
    "    df = pd.read_csv(raw_dft_path, low_memory=False)\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "    SHEFF_CODE = \"E08000019\"\n",
    "    keep_cols = [\n",
    "        \"count_point_id\", \"year\", \"local_authority_name\", \"local_authority_code\",\n",
    "        \"road_name\", \"road_type\", \"road_category\",\n",
    "        \"all_motor_vehicles\", \"latitude\", \"longitude\"\n",
    "    ]\n",
    "    df = df[[c for c in keep_cols if c in df.columns]].copy()\n",
    "\n",
    "    df[\"count_point_id\"] = df[\"count_point_id\"].astype(str)\n",
    "    if \"year\" in df:\n",
    "        df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
    "\n",
    "    df[\"all_motor_vehicles\"] = pd.to_numeric(df[\"all_motor_vehicles\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"all_motor_vehicles\"])\n",
    "\n",
    "    df_sheff = df[\n",
    "        (df[\"local_authority_code\"] == SHEFF_CODE) |\n",
    "        (df[\"local_authority_name\"].astype(str).str.fullmatch(r\"Sheffield\", na=False))\n",
    "    ].copy()\n",
    "\n",
    "    if \"road_type\" in df_sheff.columns:\n",
    "        df_sheff = df_sheff[~df_sheff[\"road_type\"].str.contains(\"Minor\", case=False, na=False)]\n",
    "\n",
    "    print(\"Sheffield filtered shape:\", df_sheff.shape)\n",
    "    df_sheff.to_csv(df_sheff_path, index=False)\n",
    "    print(\"Saved cleaned Sheffield file to:\", df_sheff_path)\n",
    "    return df_sheff\n",
    "\n",
    "\n",
    "df_sheff = load_sheffield_data(DF_SHEFF_CSV, RAW_DFT_CSV)\n",
    "\n",
    "print(\"CLEANED Sheffield AADF Data (first 10 rows)\")\n",
    "display(df_sheff.head(10))\n",
    "print(\"Dataset size:\", df_sheff.shape)\n",
    "\n",
    "# Compute maximum all_motor_vehicles and period\n",
    "max_vehicles = df_sheff[\"all_motor_vehicles\"].max()\n",
    "max_row = df_sheff[df_sheff[\"all_motor_vehicles\"] == max_vehicles]\n",
    "\n",
    "print(\"\\nRow with max all_motor_vehicles:\")\n",
    "print(max_row.to_string(index=False))\n",
    "\n",
    "peak_percentage = 0.10  # 10% peak hour assumption\n",
    "period = 3600 / (max_vehicles * peak_percentage)\n",
    "\n",
    "print(f\"\\nMax AADF (vehicles/day): {max_vehicles}\")\n",
    "print(f\"Assumed peak fraction: {peak_percentage * 100:.0f}% of daily flow\")\n",
    "print(f\"Computed PERIOD for randomTrips.py: {period:.3f} seconds between vehicles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "620089d5-618b-414f-b880-c43f2fd0a631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route file already exists: C:\\Users\\manda\\OneDrive\\Documents\\AI Traffic - Jupyter\\my_routes.rou.xml\n"
     ]
    }
   ],
   "source": [
    "def generate_random_routes(\n",
    "    network_file: Path,\n",
    "    route_file: Path,\n",
    "    period: float,\n",
    "    seed: int = 42,\n",
    "    binomial: int = 10,\n",
    "    prefix: str = \"trip\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Call SUMO's randomTrips.py to generate a realistic route file\n",
    "    based on the given network and vehicle spawn period.\n",
    "    \"\"\"\n",
    "    tools_dir = Path(SUMO_HOME) / \"tools\"\n",
    "    random_trips_py = tools_dir / \"randomTrips.py\"\n",
    "\n",
    "    if not random_trips_py.exists():\n",
    "        raise FileNotFoundError(f\"randomTrips.py not found at: {random_trips_py}\")\n",
    "\n",
    "    print(\"Generating routes with randomTrips.py ...\")\n",
    "    cmd = [\n",
    "        \"python\", str(random_trips_py),\n",
    "        \"-n\", str(network_file),\n",
    "        \"-r\", str(route_file),\n",
    "        \"--period\", str(period),\n",
    "        \"--seed\", str(seed),\n",
    "        \"--binomial\", str(binomial),\n",
    "        \"--prefix\", prefix,\n",
    "        \"--validate\",\n",
    "    ]\n",
    "\n",
    "    print(\"Command:\", \" \".join(cmd))\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(\"randomTrips.py STDERR:\\n\", result.stderr)\n",
    "        raise RuntimeError(f\"randomTrips.py failed with code {result.returncode}\")\n",
    "\n",
    "    print(\"Random Trips Generation: SUCCESS\")\n",
    "    print(\"Output routes file:\", route_file)\n",
    "\n",
    "\n",
    "# Only regenerate if you want fresh routes\n",
    "if not ROUTE_FILE.exists():\n",
    "    generate_random_routes(NETWORK_FILE, ROUTE_FILE, period)\n",
    "else:\n",
    "    print(\"Route file already exists:\", ROUTE_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbfbecd3-a9fa-4135-af6e-5d92d06f0435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote SUMO config to: C:\\Users\\manda\\OneDrive\\Documents\\AI Traffic - Jupyter\\my_config.sumocfg\n"
     ]
    }
   ],
   "source": [
    "def create_sumo_config(config_path: Path, net_file: Path, route_file: Path, tripinfo_path: Path):\n",
    "    \"\"\"\n",
    "    Create a simple SUMO configuration file that:\n",
    "      - loads the given network + route file\n",
    "      - simulates 0–3600 seconds\n",
    "      - writes tripinfo XML\n",
    "    \"\"\"\n",
    "    config_xml = f\"\"\"<configuration>\n",
    "    <input>\n",
    "        <net-file value=\"{net_file.name}\"/>\n",
    "        <route-files value=\"{route_file.name}\"/>\n",
    "    </input>\n",
    "\n",
    "    <time>\n",
    "        <begin value=\"0\"/>\n",
    "        <end value=\"3600\"/>\n",
    "    </time>\n",
    "\n",
    "    <report>\n",
    "        <verbose value=\"true\"/>\n",
    "        <no-step-log value=\"true\"/>\n",
    "    </report>\n",
    "\n",
    "    <output>\n",
    "        <tripinfo-output value=\"{tripinfo_path.name}\"/>\n",
    "    </output>\n",
    "</configuration>\n",
    "\"\"\"\n",
    "    config_path.write_text(config_xml, encoding=\"utf-8\")\n",
    "    print(\"Wrote SUMO config to:\", config_path)\n",
    "\n",
    "\n",
    "create_sumo_config(CONFIG_FILE, NETWORK_FILE, ROUTE_FILE, TRIPINFO_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d7eaf13-8487-4038-8418-ae6bd073b089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<configuration>\n",
      "    <input>\n",
      "        <net-file value=\"my_network.net.xml\"/>\n",
      "        <route-files value=\"my_routes.rou.xml\"/>\n",
      "    </input>\n",
      "\n",
      "    <time>\n",
      "        <begin value=\"0\"/>\n",
      "        <end value=\"3600\"/>\n",
      "    </time>\n",
      "\n",
      "    <report>\n",
      "        <verbose value=\"true\"/>\n",
      "        <no-step-log value=\"true\"/>\n",
      "    </report>\n",
      "\n",
      "    <output>\n",
      "        <tripinfo-output value=\"tripinfo_baseline.xml\"/>\n",
      "    </output>\n",
      "</configuration>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(CONFIG_FILE.read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9fecbd0-76ad-4661-9bf7-5747714f6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import sys\n",
    "\n",
    "def get_sumo_binary(gui: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Find the SUMO binary (sumo or sumo-gui).\n",
    "    1) Try from PATH\n",
    "    2) Fallback to SUMO_HOME/bin on Windows/Linux\n",
    "    \"\"\"\n",
    "    base_name = \"sumo-gui\" if gui else \"sumo\"\n",
    "\n",
    "    # 1) Try from PATH\n",
    "    cmd = shutil.which(base_name)\n",
    "    if cmd is not None:\n",
    "        return cmd\n",
    "\n",
    "    # 2) Try from SUMO_HOME/bin\n",
    "    if SUMO_HOME is None:\n",
    "        raise EnvironmentError(\n",
    "            f\"{base_name} not found in PATH and SUMO_HOME is not set.\\n\"\n",
    "            \"Either add SUMO to PATH, or set SUMO_HOME correctly.\"\n",
    "        )\n",
    "\n",
    "    bin_dir = Path(SUMO_HOME) / \"bin\"\n",
    "    if sys.platform.startswith(\"win\"):\n",
    "        candidate = bin_dir / f\"{base_name}.exe\"\n",
    "    else:\n",
    "        candidate = bin_dir / base_name\n",
    "\n",
    "    if not candidate.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"{base_name} not found.\\n\"\n",
    "            f\"Tried PATH and: {candidate}\\n\"\n",
    "            f\"Check that SUMO is correctly installed.\"\n",
    "        )\n",
    "\n",
    "    return str(candidate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48999fa5-b319-4cc3-af62-4f333dff042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sumo_baseline(config_file: Path, tripinfo_file: Path, use_gui: bool = False):\n",
    "    \"\"\"\n",
    "    Run SUMO using the given config file.\n",
    "    Let SUMO's built-in fixed-time signals control the junctions.\n",
    "    \"\"\"\n",
    "    if tripinfo_file.exists():\n",
    "        print(\"Deleting old tripinfo file:\", tripinfo_file)\n",
    "        tripinfo_file.unlink()\n",
    "\n",
    "    sumo_bin = get_sumo_binary(gui=use_gui)\n",
    "    print(\"Using SUMO binary:\", sumo_bin)\n",
    "\n",
    "    cmd = [\n",
    "        sumo_bin,\n",
    "        \"-c\", str(config_file),\n",
    "        \"--duration-log.statistics\",\n",
    "        \"--log\", \"log_baseline.txt\",\n",
    "    ]\n",
    "    print(\"Running SUMO baseline...\")\n",
    "    print(\"Command:\", \" \".join(cmd))\n",
    "\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(\"\\nSUMO STDERR:\\n\", result.stderr)\n",
    "        raise RuntimeError(f\"SUMO exited with code {result.returncode}\")\n",
    "\n",
    "    print(\"SUMO baseline run completed.\")\n",
    "    print(\"Tripinfo generated:\", tripinfo_file.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d62d22cc-bd02-4865-8554-61a8277f4713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SUMO binary: C:\\Program Files (x86)\\Eclipse\\Sumo\\bin\\sumo.EXE\n",
      "Running SUMO baseline...\n",
      "Command: C:\\Program Files (x86)\\Eclipse\\Sumo\\bin\\sumo.EXE -c C:\\Users\\manda\\OneDrive\\Documents\\AI Traffic - Jupyter\\my_config.sumocfg --duration-log.statistics --log log_baseline.txt\n",
      "SUMO baseline run completed.\n",
      "Tripinfo generated: True\n"
     ]
    }
   ],
   "source": [
    "run_sumo_baseline(CONFIG_FILE, TRIPINFO_FILE, use_gui=False)  # or True if you want to see the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d0820ba-9aec-458f-b86a-edbc1ba990cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed trips: 5327\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>veh_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>waiting_time</th>\n",
       "      <th>route_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trip2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trip12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trip23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trip16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trip37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   veh_id  duration  waiting_time  route_length\n",
       "0   trip2       3.0           0.0          6.21\n",
       "1  trip12       3.0           0.0          9.85\n",
       "2  trip23       1.0           0.0          0.00\n",
       "3  trip16       4.0           0.0         15.65\n",
       "4  trip37       1.0           0.0          0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fixed-time baseline metrics ===\n",
      "Average travel time (s): 66.43007321193917\n",
      "Average waiting time (s): 49.38182842125023\n",
      "Total waiting time (s): 263057.0\n",
      "Total vehicles: 5327\n"
     ]
    }
   ],
   "source": [
    "def parse_tripinfo(tripinfo_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse a SUMO tripinfo XML file into a pandas DataFrame with\n",
    "    travel time and waiting time per vehicle.\n",
    "    \"\"\"\n",
    "    if not tripinfo_path.exists():\n",
    "        raise FileNotFoundError(f\"Tripinfo file not found: {tripinfo_path}\")\n",
    "\n",
    "    records = []\n",
    "    tree = ET.parse(tripinfo_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for trip in root.iter(\"tripinfo\"):\n",
    "        veh_id = trip.get(\"id\")\n",
    "        duration = float(trip.get(\"duration\", 0.0))\n",
    "        waiting_time = float(trip.get(\"waitingTime\", 0.0))\n",
    "        route_length = float(trip.get(\"routeLength\", 0.0))\n",
    "\n",
    "        records.append({\n",
    "            \"veh_id\": veh_id,\n",
    "            \"duration\": duration,\n",
    "            \"waiting_time\": waiting_time,\n",
    "            \"route_length\": route_length,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_tripinfo = parse_tripinfo(TRIPINFO_FILE)\n",
    "print(\"Parsed trips:\", len(df_tripinfo))\n",
    "display(df_tripinfo.head())\n",
    "\n",
    "print(\"\\n=== Fixed-time baseline metrics ===\")\n",
    "print(\"Average travel time (s):\", df_tripinfo[\"duration\"].mean())\n",
    "print(\"Average waiting time (s):\", df_tripinfo[\"waiting_time\"].mean())\n",
    "print(\"Total waiting time (s):\", df_tripinfo[\"waiting_time\"].sum())\n",
    "print(\"Total vehicles:\", len(df_tripinfo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39910557-7186-46b5-8af2-1fc30bdac811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
